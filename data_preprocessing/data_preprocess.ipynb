{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e2f08e-1625-46bc-906e-72b50bbb8e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in ./.local/lib/python3.8/site-packages (1.6.3)\n"
     ]
    }
   ],
   "source": [
    "# !  pip install emoji-translate spacy\n",
    "# !pip install googletrans\n",
    "# !pip install googletrans==4.0.0-rc1\n",
    "! pip install emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2617452-9866-4eb7-851e-006ae166fd30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datasets \n",
    "from datasets import load_dataset\n",
    "from emoji_translate.emoji_translate import Translator\n",
    "import googletrans \n",
    "emo = Translator(exact_match_only=False, randomize=True)\n",
    "import re\n",
    "from emoji import UNICODE_EMOJI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81380d5b-52cb-48b7-853e-ac22d688f04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_emoji(s, language=\"en\"):\n",
    "    return s in UNICODE_EMOJI[language]\n",
    "\n",
    "# add space near your emoji\n",
    "def add_space(text):\n",
    "    return ''.join(' ' + char if is_emoji(char) else char for char in text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4196c319-b248-441d-98f9-13c6992429a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datset = pd.read_csv('/home/aatef/boda/ar_hate_speech_2022/data/OSACT2022-sharedTask-train.txt', sep='\\t', header=None, index_col=0, names = ['sentence', 'OF_label','HS_label','Vulgar_label','Violence_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f48ac318-e301-4ff3-8537-248d78171972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset  = datasets.Dataset.from_pandas(train_datset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29467709-9f68-4de4-aa50-34986a2a8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5dd3079-c515-47ef-a885-441d63b0cc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@USER ردينا ع التطنز 😏👊🏻',\n",
       " 'وصارت فطاير البقالات غذاء صحي 👎🏻 URL',\n",
       " '@USER روحي لبريده تلقين اشباه كثير بس ماحد زيكم مشفوح يخقخق ويطالعهم بكل انحطاط ويصورهم الله يفشلكم بس😷',\n",
       " '@USER مش باين حاجه خالص 😣<LF>مش عارف بقى 😔',\n",
       " '#اليوم_الاثنين<LF><LF>👏 يقولك :%90  من المسلمين <LF>عندهم خاله اسمها امل<LF>👏أو عمه امل <LF>👏او اخت امل<LF>👏او زوجه امل<LF>👏او بنت امل<LF>✊او حماة امل<LF>👊واللي ماعنده ولا امل<LF>بالعائلة يراجع نفسه لانه وضعه مو طبيعي/😳<LF>وأي قروب فيه \"امل\" هو من أسعد القروبات<LF>اذا عندكم وحده اسمها امل ارسلوها لها😽😻',\n",
       " 'حمدلله ماحطها في فمي اساسا😷🤢 URL',\n",
       " '@USER هههه 😂🌚🤢',\n",
       " '#بايع_الكليجا اللي مايضحك من هالمقطع يبلكني هههههههه مطططههببللللل 😂😂😂👌👌👊👊😍😍😩😩😂😂 يمثلني ههههههه 😂😂👊 URL',\n",
       " 'خلاص الله يزعجكم خلللاص 😷😷 #بايع_الكليجا',\n",
       " '@USER هيلق و جحلط غير كذا مافي 😷']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[:10]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a4d60b85-1e4d-425d-a775-a04ef248db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "translator = googletrans.Translator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d54e9844-f87f-4624-aa08-950abdf58e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ردينا ع التطنز asd facepunch light skin tone\n",
      "smirk\n",
      "ردينا ع التطنز smirk facepunch light skin tone\n",
      "ردينا ع التطنز asd asd light skin tone\n",
      "facepunch\n",
      "ردينا ع التطنز smirk facepunch light skin tone\n",
      "ردينا ع التطنز asd asd asd skin tone\n",
      "light\n",
      "ردينا ع التطنز smirk facepunch light skin tone\n",
      "ردينا ع التطنز asd asd asd asd tone\n",
      "skin\n",
      "ردينا ع التطنز smirk facepunch light skin tone\n",
      "ردينا ع التطنز asd asd asd asd asd\n",
      "tone\n",
      "ردينا ع التطنز smirk facepunch light skin tone\n"
     ]
    }
   ],
   "source": [
    "\n",
    "s = 'ردينا ع التطنز smirk facepunch light skin tone'\n",
    "\n",
    "en_words = re.finditer(r'[A-Za-z]+', s)\n",
    "for match  in en_words:\n",
    "    cur = str(match.group())\n",
    "    s = re.sub(cur,'asd', s)\n",
    "    print(s)\n",
    "    print(match.group())\n",
    "    print(match.string)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bfc4952b-29b6-4c65-a516-5a42cb8e63e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(example):\n",
    "    \n",
    "    example['sentence'] = example['sentence'].replace('@USER', '') \\\n",
    "    .replace('URL', '') \\\n",
    "    .replace('<LF>','') \\\n",
    "    .replace('/', ' ') \\\n",
    "    .replace ('#', ' ')\n",
    "\n",
    "    \n",
    "    s = ''\n",
    "    for i,c in  enumerate(example['sentence']):\n",
    "        if is_emoji(c):\n",
    "            s+= ' ' + c + ' '\n",
    "        else:\n",
    "            s+= c\n",
    "       \n",
    "    example['sentence'] = s \n",
    "    example['sentence'] = re.sub(' +', ' ', example['sentence'])\n",
    "    \n",
    "#     example['sentence'] =  add_space(example['sentence'])\n",
    "    \n",
    "    print( example['sentence'])\n",
    "    \n",
    "    example['sentence'] = emo.demojify (example['sentence'])\n",
    "\n",
    "    en_words = re.finditer(r'[A-Za-z]+', example['sentence'])\n",
    "    for match  in en_words:\n",
    "        cur = str(match.group())\n",
    "        example['sentence'] = re.sub(cur,translator.translate(cur, dest='ar').text, example['sentence'])  \n",
    "\n",
    "    example['sentence'] = translator.translate( example['sentence'], dest='ar').text\n",
    "    \n",
    "    # print( example['sentence'])\n",
    "    \n",
    "    example['OF_label'] =  1 if example['OF_label'] == 'OFF' else 0\n",
    "    example['Vulgar_label'] =  1 if example['Vulgar_label'] == 'VLG' else 0\n",
    "    example['Violence_label'] =  1 if example['Violence_label'] == 'VIO' else 0\n",
    "    example['HS_label'] =  0 if example['HS_label'] == 'NOT_HS' else int(example['HS_label'][2:])\n",
    "    \n",
    "    return example\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "983175a3-7078-4a21-9726-af131934a173",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function process at 0x2aaba1da3820> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4838d5cdf4485b9036cdf7c4d35131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0ex [00:00, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ردينا ع التطنز 😏 👊 🏻 \n",
      "ردينا ع التطنز سميرك وجه لكمة خفيفة جلد نغمة\n",
      "وصارت فطاير البقالات غذاء صحي 👎 🏻 \n",
      "وصارت فطاير البقالات غذاء صحي -1 خفيفة جلد نغمة\n",
      " روحي لبريده تلقين اشباه كثير بس ماحد زيكم مشفوح يخقخق ويطالعهم بكل انحطاط ويصورهم الله يفشلكم بس 😷 \n",
      "روحي لبريده تلقين اشباه كثير بس ماحد زيكم مشفوح يخقخق ويطالعهم بكل انحطاط ويصورهم الله يفشلكم بس قناع\n",
      " مش باين حاجه خالص 😣 مش عارف بقى 😔 \n",
      "مش باين حاجه خالص ثابر مش عارف بقى متأمل\n",
      "#اليوم_الاثنين 👏 يقولك :%90 من المسلمين عندهم خاله اسمها امل 👏 أو عمه امل 👏 او اخت امل 👏 او زوجه امل 👏 او بنت امل ✊ او حماة امل 👊 واللي ماعنده ولا املبالعائلة يراجع نفسه لانه وضعه مو طبيعي/ 😳 وأي قروب فيه \"امل\" هو من أسعد القروباتاذا عندكم وحده اسمها امل ارسلوها لها 😽 😻 \n",
      "#اليوم_الاثنين التصفيق يقولك :%90 من المسلمين عندهم خاله اسمها امل التصفيق أو عمه امل التصفيق او اخت امل التصفيق او زوجه امل التصفيق او بنت امل قبضة او حماة امل وجه لكمة واللي ماعنده ولا املبالعائلة يراجع نفسه لانه وضعه مو طبيعي/ ضجة وأي قروب فيه \"امل\" هو من أسعد القروباتاذا عندكم وحده اسمها امل ارسلوها لها تقبيل قط قلب عيون قط\n",
      "حمدلله ماحطها في فمي اساسا 😷 🤢 \n",
      "حمدلله ماحطها في فمي اساسا قناع قرفان وجه\n",
      " هههه 😂 🌚 🤢 \n",
      "هههه مرح الجديد القمر مع وجه قرفان وجه\n",
      "#بايع_الكليجا اللي مايضحك من هالمقطع يبلكني هههههههه مطططههببللللل 😂 😂 😂 👌 👌 👊 👊 😍 😍 😩 😩 😂 😂 يمثلني ههههههه 😂 😂 👊 \n",
      "#بايع_الكليجا اللي مايضحك من هالمقطع يبلكني هههههههه مطططههببللللل مرح مرح مرح موافق كف موافق كف وجه لكمة وجه لكمة قلب عيون قلب عيون المرهق المرهق مرح مرح يمثلني ههههههه مرح مرح وجه لكمة\n",
      "خلاص الله يزعجكم خلللاص 😷 😷 #بايع_الكليجا\n",
      "خلاص الله يزعجك خلاص قناع قناع #بايع_الكليجا\n",
      " هيلق و جحلط غير كذا مافي 😷 \n",
      "هيلق و جحلط غير كذا مافي قناع\n"
     ]
    }
   ],
   "source": [
    "processed_train_dataset = train_dataset.map(process,num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79412fb2-89c8-48bd-ad5b-686c8bf66013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['ردينا ع التطنز سميرك وجه لكمة خفيفة جلد نغمة',\n",
       "  'وصارت فطاير البقالات غذاء صحي -1 خفيفة جلد نغمة',\n",
       "  'روحي لبريده تلقين اشباه كثير بس ماحد زيكم مشفوح يخقخق ويطالعهم بكل انحطاط ويصورهم الله يفشلكم بس قناع',\n",
       "  'مش باين حاجه خالص ثابر مش عارف بقى متأمل',\n",
       "  '#اليوم_الاثنين التصفيق يقولك :%90 من المسلمين عندهم خاله اسمها امل التصفيق أو عمه امل التصفيق او اخت امل التصفيق او زوجه امل التصفيق او بنت امل قبضة او حماة امل وجه لكمة واللي ماعنده ولا املبالعائلة يراجع نفسه لانه وضعه مو طبيعي/ ضجة وأي قروب فيه \"امل\" هو من أسعد القروباتاذا عندكم وحده اسمها امل ارسلوها لها تقبيل قط قلب عيون قط'],\n",
       " 'OF_label': [1, 0, 1, 0, 0],\n",
       " 'HS_label': [0, 0, 0, 0, 0],\n",
       " 'Vulgar_label': [0, 0, 0, 0, 0],\n",
       " 'Violence_label': [0, 0, 0, 0, 0],\n",
       " '__index_level_0__': [1, 2, 3, 4, 5]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7dee1-9a57-4d8e-b86b-27a4544206ee",
   "metadata": {},
   "source": [
    "## TODO \n",
    " - remove english words before you convert emojis \n",
    " - go over words and translate english ones \n",
    " - convert numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cca68e5-8502-4113-a5fa-b111c9aad251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70d32ede0a0465bc8b96545a3ec0778cfbc69f464a1993b76f864f8a73578c78"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
